d3.select("#description")
    .append("div")
        .attr("id", "description-top-button-container")
        .on("click", function() {
            document.body.scrollTop = 0; // For Safari
            document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
        })
d3.select("#description-top-button-container")
    .append("img")
        .attr("src", "icons/top.svg")
        .attr("id", "description-top-button-img")
d3.select("#description-top-button-container")
    .append("div")
        .attr("id", "description-top-button-text")
        .text("top")
d3.select("#description")
    .append("div")
        .attr("id", "description-section-what")
        .attr("class", "description-sec")
        .append("h1")
            .text("Stable Diffusionとは何ですか?")
d3.select("#description-section-what")
    .append("p")
        .html(`
Stable Diffusionは、テキスト・プロンプトを高解像度の画像に変換するテキスト画像生成モデルです。
例えば、<span style="color: var(--text3);">かわいくて愛らしいうさぎ</span>と入力すると、Stable Diffusionは数秒でそれを描いた高解像度の画像&mdash; <span style="color: var(--text3);">かわいくて愛らしいうさぎ</span> &mdash;
を生成します。
Diffusion Explainerで「別のプロンプトを選択」をクリックして、プロンプトを変更し、各プロンプトから生成される魅力的な画像をチェックしてみてください！
`)

// How does Stable Diffusion work?
d3.select("#description")
    .append("div")
        .attr("id", "description-section-how-work")
        .attr("class", "description-sec")
        .append("h1")
            .text("Stable Diffusionはどのように動作しますか？")
d3.select("#description-section-how-work")
    .append("p")
        // .text('Stable Diffusion first generates a vector representation of an image depicted in the text prompt. This image representation is then upscaled into a high-resolution image.')
        .html(`
Stable Diffusionは、まずテキスト・プロンプトを<span style="font-style: italic">テキスト表現</span>に変換します。
これは、プロンプトを要約する数値です。
このテキスト表現は<span style="font-style: italic">画像表現</span>の生成に使用され、
画像表現はテキスト・プロンプトで描かれた画像を要約します。
この画像表現は、その後高解像度の画像にアップスケールされます。
        `)
d3.select("#description-section-how-work")
    .append("p")
        // .html('You may wonder why Stable Diffusion introduces image representation instead of directly generating high-resolution images. The reason is <span style="font-style: italic;">computational cost efficiency</span>. Doing most computations on representation, which summarizes an image in a compact form, significantly reduces the computational cost while maintaining high image quality.')
        .html(`
なぜStable Diffusionが高解像度画像を直接生成する代わりに画像表現を導入するのか疑問に思うかもしれません。
その理由は<span style="font-style: italic">計算効率</span>です。
高解像度画像ではなくコンパクトな画像表現でほとんどの計算を行うことで、高い画像品質を維持しながら計算時間とコストを大幅に削減できます。
        `)
d3.select("#description-section-how-work")
    .append("p")
        // .html('The image representation starts as a random noise and is refined over multiple timesteps to reach the image representation for your text prompt. The number of timesteps is a hyperparameter determined before refining and typically set to 50.')
        .html(`
ランダムノイズから始まる画像表現は、
複数のタイムステップにわたって洗練され、テキスト・プロンプトに強く準拠した高品質画像の画像表現に到達します。
洗練のタイムステップ数は通常50または100に設定されます。Diffusion Explainerでは50に固定しています。
        `)
d3.select("#description-section-how-work")
    .append("p")
        .html('Stable Diffusionの画像生成プロセスを3つの主要なステップに分解します：')
        .append("ol")
        .attr("id", "description-generation-main-steps-ol")
d3.select("#description-generation-main-steps-ol")
    .append("li")
        .html('<a style="font-weight: 500" href="#description-subsec-text-representation-generation">テキスト表現生成</a>：Stable Diffusionはテキスト・プロンプトをテキスト・ベクトル表現に変換します。')
d3.select("#description-generation-main-steps-ol")
    .append("li")
        .html('<a style="font-weight: 500" href="#description-subsec-image-representation-refining">画像表現の洗練</a>：ランダムノイズから始めて、Stable Diffusionはテキスト表現のガイダンスのもと、画像表現を少しずつ洗練していきます。Stable Diffusionは複数のタイムステップ（私たちのDiffusion Explainerでは50）にわたってこの洗練を繰り返します。')
d3.select("#description-generation-main-steps-ol")
    .append("li")
        .html('<a style="font-weight: 500" href="#description-subsec-image-upscaling">画像アップスケーリング</a>：Stable Diffusionは画像表現を高解像度画像にアップスケールします。')
d3.select("#description-section-how-work")
    .append("p")
        .text("では、各プロセスをより詳しく見ていきましょう。")

// Text Representation Generation
d3.select("#description-section-how-work")
    .append("div")
        .attr("id", "description-subsec-text-representation-generation")
        .attr("class", "description-subsec")
        .append("h2")
            .text("テキスト表現生成")
d3.select("#description-subsec-text-representation-generation")
    .append("img")
        .attr("class", "description-gif")
        .attr("id", "text-representation-generation-expansion-gif")
        .attr("src", "assets/gif/trg.gif")
d3.select("#description-subsec-text-representation-generation")
    .append("p")
        // .text("Text representation generation consists of tokenizing and text encoding.")
        .html(`
テキスト表現生成をクリックすると、テキスト・プロンプトがプロンプトを要約するベクトルであるテキスト表現に変換される方法が表示されます。
これは2つのステップで構成されます：
<span style="font-style: italic">トークン化</span>
と
<span style="font-style: italic">テキスト・エンコーディング</span>
です。
        `)
// Tokenizing
d3.select("#description-subsec-text-representation-generation")
    .append("div")
        .attr("id", "description-subsubsec-tokenizing")
        .attr("class", "description-subsubsec")
d3.select("#description-subsubsec-tokenizing")
    .append("div")
        .attr("class", "description-subsubsec-title")
        .html('1. トークン化')
d3.select("#description-subsubsec-tokenizing")
    .append("p")
        // .html("Tokenizing is a common way to handle text input to standardize the format of the input and enable the text input to be processed by neural networks.")
        .html(`トークン化は、テキストを数値に変換してニューラルネットワークで処理するために、テキストデータを扱う一般的な方法です。`)
d3.select("#description-subsubsec-tokenizing")
    .append("div")
        .attr("class", "description-paragraph")
        .attr("id", "description-subsubsec-tokenizing-token-example-paragraph")



d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
    .html(`Stable Diffusionはテキスト・プロンプトをトークンのシーケンスにトークン化します。
   例えば、テキスト・プロンプト `)
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .style("color", "var(--text3)")
        .text("a cute and adorable bunny は")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("a")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("cute")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("and")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("adorable")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("bunny")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(" にトークン化されます。")



d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text("また、プロンプトの始まりと終わりを示すため、Stable Diffusion は ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("<start>")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(" や ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("<end>")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(" といったトークンをトークン群の最初と最後に追加します。")


d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text("上記の例の結果となるトークンシーケンスは以下のようになります。")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("<start>")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("a")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("cute")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("and")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("adorable")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("bunny")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .text(", ")
d3.select("#description-subsubsec-tokenizing-token-example-paragraph")
    .append("span")
        .attr("class", "text-vector-generator-token description-token")
        .text("<end>")



d3.select("#description-subsubsec-tokenizing")
    .append("p")
        // .html('To ensure that all token sequences have the same length for easier computation, Stable Diffusion pads or truncates the token sequences to exactly 77 tokens. If the input prompt has fewer than 77 tokens, <span class="text-vector-generator-token description-token" id="description-token-end"></span> tokens are added to the end of the sequence until it reaches 77 tokens. If the input prompt has more than 77 tokens, the last 77 tokens are retained and the rest are truncated. The number of tokens was set to balance performance and computational efficiency.')
        .html('計算を簡単にするため、Stable Diffusionはパディングまたは切り詰めによって、すべてのテキスト・プロンプトのトークンシーケンスを同じ長さの77に保ちます。入力プロンプトが77トークン未満の場合、<span class="text-vector-generator-token description-token" id="description-token-end"></span>トークンが77トークンに達するまでシーケンスの末尾に追加されます。入力プロンプトが77トークンを超える場合、最初の77トークンが保持され、残りは切り詰められます。77という長さは、性能と計算効率のバランスを取るために設定されました。')
d3.select("#description-token-end").text("<end>")
// Text encoding
d3.select("#description-subsec-text-representation-generation")
    .append("div")
        .attr("id", "description-subsubsec-text-encoding")
        .attr("class", "description-subsubsec")
d3.select("#description-subsubsec-text-encoding")
    .append("div")
        .attr("class", "description-subsubsec-title")
        .html('2. テキスト・エンコーディング')
d3.select("#description-subsubsec-text-encoding")
    .append("p")
        .html(`Stable Diffusionはトークンシーケンスをテキスト表現に変換します。画像生成のガイダンスにテキスト表現を使用するため、Stable Diffusionはテキスト表現がプロンプトで描かれた画像に関連する情報を含むことを保証します。これは<a href="https://openai.com/research/clip">CLIP</a>と呼ばれる特別なニューラルネットワークを使用することで行われます。
`)
d3.select("#description-subsubsec-text-encoding")
    .append("p")
        .html("画像エンコーダーとテキスト・エンコーダーで構成されるCLIPは、画像とそのテキスト記述を互いに似たベクトルにエンコードするよう訓練されています。したがって、CLIPのテキスト・エンコーダーによって計算されたプロンプトのテキスト表現は、プロンプトで記述された画像に関する情報を含んでいる可能性が高いです。上記のText Encoderをクリックすることで視覚的説明を表示できます。")

// Image Representation Refining
d3.select("#description-section-how-work")
    .append("div")
        .attr("id", "description-subsec-image-representation-refining")
        .attr("class", "description-subsec")
        .append("h2")
            .text("画像表現の洗練")
d3.select("#description-subsec-image-representation-refining")
    .append("img")
        .attr("class", "description-gif")
        .attr("id", "image-refining-description-gif")
        .attr("src", "assets/gif/irr.gif")
d3.select("#description-subsec-image-representation-refining")
    .append("p")
        .html("Stable Diffusionは、テキスト・プロンプトで描かれた高解像度画像を数値的に要約するベクトルである画像表現を生成します。これは、ランダムに初期化されたノイズを複数のタイムステップにわたって洗練し、画像品質とプロンプトへの準拠性を徐々に改善することで行われます。Diffusion Explainerの<span style='font-style: italic;'>シード</span>を調整することで、初期のランダムノイズを変更できます。Image Representation Refinerをクリックして、ノイズ予測と除去を含む各洗練ステップを視覚化してください。")

// Noise Prediction
d3.select("#description-subsec-image-representation-refining")
    .append("div")
        .attr("id", "description-subsubsec-noise-prediction")
        .attr("class", "description-subsubsec")
d3.select("#description-subsubsec-noise-prediction")
    .append("div")
        .attr("class", "description-subsubsec-title")
        .html('1. ノイズ予測')
d3.select("#description-subsubsec-noise-prediction")
    .append("p")
        .html("各タイムステップにおいて、UNetと呼ばれるニューラルネットワークが現在のタイムステップの画像表現のノイズを予測します。UNetは3つの入力を受け取ります：")
d3.select("#description-subsubsec-noise-prediction")
    .append("ol")
        .attr("id", "description-unet-input-ol")
d3.select("#description-unet-input-ol")
    .append("li")
    .html(`現在のタイムステップの<span style="font-weight: 500;">画像表現</span>`)
d3.select("#description-unet-input-ol")
    .append("li")
    .html(`テキスト・プロンプトに準拠した画像を生成するために現在の画像表現からどのノイズを除去すべきかをガイドする、プロンプトの<span style="font-weight: 500; color: var(--text3);">テキスト表現</span>`)
d3.select("#description-unet-input-ol")
    .append("li")
    .html(`現在の画像表現に残っているノイズの量を示す<span style="font-weight: 500;">タイムステップ</span>`)

d3.select("#description-subsubsec-noise-prediction")
    .append("p")
        .html(`言い換えると、UNetはテキスト・プロンプトの表現とタイムステップのガイダンスのもと、現在の画像表現における<span style="color: var(--text3);">プロンプト条件付きノイズ</span>を予測します。`)
d3.select("#description-subsubsec-noise-prediction")
    .append("p")
        .html(`しかし、ノイズ予測をテキスト・プロンプトで条件付けしても、生成された画像表現は通常、テキスト・プロンプトに十分強く準拠しません。
準拠性を改善するため、Stable Diffusionは追加で<span style="color: #909090;">空のプロンプト（" "）で条件付けされた汎用ノイズ</span>を予測し、プロンプト条件付きノイズからそれを減算することで、プロンプトの影響を測定します：`) 
        // The final noise prediction is a weighted sum of the predicted 
        // <span style="color: #a0a0a0;">generic noise</span> and the
        // <span style="color: var(--text3);">prompt-conditioned noise</span>
        // with the weights controlled by the hyperparameter <span style="font-weight: 500;">guidance scale</span>:`)
d3.select("#description-subsubsec-noise-prediction")
    .append("p")
        .attr("class", "description-equation")
        .html(`
        <span class="description-equation-term" style="color: var(--text3); background-color: #4d922110;">impact of prompt</span> 
        <span class="description-equation-op">=</span> 
        <span class="description-equation-term" style="color: var(--text3); background-color: #4d922110;">prompt-conditioned noise</span> 
        <span class="description-equation-op">-</span> 
        <span class="description-equation-term" style="color: #909090; background-color: #a0a0a020;">generic noise</span>`)
d3.select("#description-subsubsec-noise-prediction")
    .append("p")
    .html(`言い換えると、汎用ノイズはより良い画像品質に貢献し、プロンプトの影響はプロンプトへの準拠性に貢献します。
最終的なノイズは、<span style="color: var(--text3);">ガイダンス・スケール</span>と呼ばれる値によって制御される、それらの重み付き和です：`)
d3.select("#description-subsubsec-noise-prediction")
    .append("p")
        .attr("class", "description-equation")
        .attr("id", "description-equation-gs")
d3.select("#description-equation-gs")
    .append("span")
        .attr("class", "description-equation-term")
        .style("background-color", "#a0a0a020")
        .style("color", "#909090")
        .text("generic noise")
d3.select("#description-equation-gs")
    .append("span")
        .attr("class", "description-equation-op")
        .text(" + ")
d3.select("#description-equation-gs")
    .append("span")
        .attr("class", "description-equation-term")
        .style("background-color", "#27641910")
        .style("color", "var(--text3)")
        .text("guidance scale")
d3.select("#description-equation-gs")
    .append("span")
        .attr("class", "description-equation-op")
        .text(" x ")
d3.select("#description-equation-gs")
    .append("span")
        .style("background-color", "#27641910")
        .style("color", "var(--text3)")
        .attr("class", "description-equation-term")
        .text("impact of prompt")
d3.select("#description-subsubsec-noise-prediction")
    .append("p")
    .html(`ガイダンス・スケールが0の場合はテキスト・プロンプトへの準拠なしを意味し、ガイダンス・スケールが1の場合は元のプロンプト条件付きノイズを使用することを意味します。
より大きなガイダンス・スケールはテキスト・プロンプトへのより強い準拠をもたらしますが、値が大きすぎると画像品質が低下する可能性があります。
Diffusion Explainerでガイダンス・スケール値を変更して、生成画像がどのように変化するかを確認してください。`)

// Noise Removal
d3.select("#description-subsec-image-representation-refining")
    .append("div")
        .attr("id", "description-subsubsec-noise-removal")
        .attr("class", "description-subsubsec")
d3.select("#description-subsubsec-noise-removal")
    .append("div")
        .attr("class", "description-subsubsec-title")
        .html('2. ノイズ除去')
d3.select("#description-subsubsec-noise-removal")
    .append("p")
        .html("Stable Diffusionは次に、スケジューラーと呼ばれるアルゴリズムによって決定される、予測されたノイズのうち実際にどの程度を画像から除去するかを決定します。少量のノイズを除去することで、画像を徐々に洗練し、よりシャープな画像を生成できます。")
d3.select("#description-subsubsec-noise-removal")
    .append("p")
        .html("スケジューラーは総タイムステップ数を考慮してこの決定を行います。ダウンスケールされたノイズは現在のタイムステップの画像表現から減算され、洗練された表現を得ます。これが次のタイムステップの画像表現となります：")
d3.select("#description-subsubsec-noise-removal")
    .append("p")
        .attr("class", "description-equation")
        .attr("id", "description-equation-denoise")
d3.select("#description-equation-denoise")
    .append("span")
        .attr("class", "description-equation-term")
        .style("background-color", "#a0a0a020")
        .html(`image representation of timestep <span style="font-style: italic;">t+1</span>`)
d3.select("#description-equation-denoise")
    .append("span")
        .attr("class", "description-equation-op")
        .html(` = `)
d3.select("#description-equation-denoise")
    .append("span")
        .attr("class", "description-equation-term")
        .style("background-color", "#a0a0a020")
        .html(`image representation of timestep <span style="font-style: italic;">t</span>`)
d3.select("#description-equation-denoise")
    .append("span")
        .attr("class", "description-equation-op")
        .html(` - `)
d3.select("#description-equation-denoise")
    .append("span")
        .attr("class", "description-equation-term")
        .style("background-color", "#a0a0a020")
        .html(`downscaled noise`)

// Image Upscaling
d3.select("#description-section-how-work")
    .append("div")
        .attr("id", "description-subsec-image-upscaling")
        .attr("class", "description-subsec")
            .append("h2")
                .text("画像アップスケーリング")
d3.select("#description-subsec-image-upscaling")
    .append("img")
    .attr("class", "description-gif")
    .attr("src", "assets/gif/upscale.gif")
d3.select("#description-subsec-image-upscaling")
    .append("p")
        .text("すべてのデノイジングステップが完了した後、Stable DiffusionはDecoderと呼ばれるニューラルネットワークを使用して、画像表現を高解像度画像にアップスケールします。テキスト表現のガイダンスによって完全にデノイジングされた洗練された画像表現は、テキスト・プロンプトに強く準拠した高解像度画像を生成します。")

// Comparison View
d3.select("#description")
    .append("div")
        .attr("id", "description-section-comparison")
        .attr("class", "description-sec")
        .append("h1")
            .text("プロンプト・キーワードは画像生成にどのような影響を与えますか？")
            .style("margin-bottom", "0.5em")
d3.select("#description-section-comparison")
    .append("img")
        .attr("class", "description-gif")
        .attr("id", "rcv-expansion-gif")
        .attr("src", "assets/gif/rcv.gif")
d3.select("#description-section-comparison")
    .append("p")
        .html(`テキスト・プロンプトの作成は非常に発見的で反復的になることがあります。
例えば、プロンプト
<span style="color: var(--text3); font-style: italic;">かわいいうさぎ</span>
から始めて、
<span style="color: var(--text3); font-style: italic;">かわいいピクサーキャラクターのスタイル</span>
などのキーワードを繰り返し追加・削除して、望む画像に到達するまで続ける必要があります。`)

d3.select("#description-section-comparison")
    .append("p")
        .text(`したがって、プロンプト・キーワードが画像生成にどのような影響を与えるかを理解することは、プロンプトの作成と改良に非常に役立ちます。
テキスト・プロンプトでハイライトされたキーワードをクリックして、そのキーワードのみが異なる2つのプロンプトの画像生成を比較してください。
`)

// What can we change
d3.select("#description")
    .append("div")
        .attr("id", "description-section-change")
        .attr("class", "description-sec")
        .append("h1")
            .text("何を変更できますか？")
d3.select("#description-section-change")
    .append("p")
        .text("私たちのDiffusion Explainerでは、生成される画像を変更するためにテキスト・プロンプトとハイパーパラメータをコントロールできます：")
d3.select("#description-section-change")
    .append("ul")
        .attr("id", "description-hyperparameter-ol")
d3.select("#description-hyperparameter-ol")
    .append("li")
    .html(`テキスト・プロンプト：生成したい画像の説明。より詳細なテキスト・プロンプトは一般的により高品質な画像につながります。`)
d3.select("#description-hyperparameter-ol")
    .append("li")
    .html(`シード：タイムステップ0での画像表現の初期化のためのランダムシード。シードを変更すると、タイムステップ0で異なる画像表現が生成され、したがって異なる画像が生成されます。`)
d3.select("#description-hyperparameter-ol")
    .append("li")
    .html(`ガイダンス・スケール：生成された画像がテキスト・プロンプトにどの程度密接に従うか。ガイダンス・スケールを上げると、より強い従属性が得られますが、生成画像が過度に誇張される可能性があります。`)
d3.select("#description-section-change")
    .append("p")
        .text("さらに、総タイムステップ数、画像サイズ、スケジューラーの種類など、Diffusion Explainerに含まれていない他のハイパーパラメータもあります。")

// How implemented?
d3.select("#description")
    .append("div")
        .attr("id", "description-section-implement")
        .attr("class", "description-sec")
        .append("h1")
            .text("Diffusion Explainerはどのように実装されていますか？")
d3.select("#description-section-implement")
    .append("p")
        .text("私たちはDiffusion ExplainerのインタラクティブなビジュアライゼーションをJavascriptとD3.jsを使用して実装しています。")

// How implemented?
d3.select("#description")
    .append("div")
        .attr("id", "description-section-who")
        .attr("class", "description-sec")
        .append("h1")
            .text("Who developed the Diffusion Explainer?")
d3.select("#description-section-who")
    .append("p")
        .html(`Diffusion Explainer は以下のメンバーによって開発されました。 
        <a href="http://www.seongmin.xyz">Seongmin Lee</a>, 
        <a href="https://bhoov.com">Ben Hoover</a>, 
        <a href="http://hendrik.strobelt.com">Hendrik Strobelt</a>, 
        <a href="https://zijie.wang">Jay Wang</a>, 
        <a href="https://shengyun-peng.github.io">Anthony Peng</a>, 
        <a href="https://www.austinpwright.com">Austin Wright</a>, 
        <a href="https://www.linkedin.com/in/kevinyli/">Kevin Li</a>, 
        <a href="https://haekyu.com">Haekyu Park</a>, 
        <a href="https://alexanderyang.me">Alex Yang</a>, 
        <a href="https://poloclub.github.io/polochau/">Polo Chau</a>.`)